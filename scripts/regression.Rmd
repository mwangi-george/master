---
title: "Regression In R"
date: "`r format(Sys.Date(), '%d %b, %Y')`"
output: 
  github_document:
    toc: yes
---

# Introduction to Linear Regression
The most basic and widely used predictive analysis is linear regression. Estimates from regression are used to describe the data and clarify the relationship.
Businesses can use linear regressions to analyze trends and provide estimates or projections. For instance, if a firm's sales have been rising gradually each month for the previous several years, the firm may anticipate sales in the months ahead by doing a linear analysis on the sales data with monthly sales. In this paper we are going to use marketing data of a certain company to explore linear regression. The data the contains advertising budget (in US dollars) for channels Tv, Radio, and Social_media, the type of influencer method, and the sales associated with each channel and influence type. 
```{r}
# load libraries
pacman::p_load(tidyverse, janitor, naniar, ggthemes, broom)

# read data
my_data <- read_csv("datasets/marketing.csv",
  show_col_types = F
) %>%
  clean_names()

# print first 6 observations
head(my_data)

# remove duplicates
my_data %>% 
  distinct() -> my_data
```

Let's determine if there are missing values in the data that might alter our analysis
```{r}
# are there NA's in the data
any_na(my_data)

# What percent of the data is missing
pct_miss(my_data)
```

Only 0.114 percent of the data is missing. We can remove the rows with missing data. Note that this is not the standard way to deal with missing values but for sake of keeping our focus on regression, let's drop NA's.
```{r}
my_data %>% 
  drop_na() -> my_data 
```

Let's start by running a simple linear regression model using sales as the dependent variable and Tv budget as the explanatory variable. Before that, it is always a good idea to visualize the data and check whether the two variables have a linear relationship. 

```{r}
my_data %>%
  ggplot(aes(tv, sales)) +
  # add a scatter plot
  geom_point() +
  # fit a linear trendline
  geom_smooth(
    method = "lm",
    se = F
  ) +
  # add a theme
  theme_clean() +
  # add correct labels
  labs(
    title = "Sales versus Tv Budget",
    x = "Tv ad Budget"
  )
```

The graph illustrates a very strong linear relationship between sales and tv budget. This means that increase in Tv advertisement budget is associated with increase in sales. Let's calculate the correlation coefficient between sales and tv budget to examine how strong the relationship is.
```{r}
my_data %>% 
  summarise(
    correlation = cor(tv, sales)
  ) %>% 
  pull(correlation)
```

The output means that there is a very strong positve correlation between sales and tv ad budget. While ggplot can display a linear regression trend line using geom_smooth(), it doesn't give us access to the intercept and slope as variables, 
or allow us to work with the model results as variables. That means that we will need to run a linear regression 
```{r}
# predict sales using Tv budget
tv_model <- lm(sales ~ tv, data = my_data)

# print tv_model
tv_model
```

Our interest is in the coefficient results. The intercept value (-0.1325) indicates that, on average, the firm loses money in sales even if it does not spend any money on television advertising. Given that we cannot make negative sales, this number is illogical. Contrarily, the slope indicates that a 1 dollar increase in the budget for television advertisements results in a 3.6 dollar rise in sales.

Let's now make a sales prediction utilizing the explanatory variable influencer. N otice that the influencer variable is categorical. To signal that all coefficients should be provided relative to zero, we instead add "+ 0" to the explanatory variable.
```{r}
influencer_model <- lm(sales ~ influencer + 0, data = my_data)

# print influencer model
influencer_model

```

The first coefficient, influencerMacro, indicates that the firm will generate an average revenue of $196.12 per transaction if it engages a Macro influencer to promote its goods. Other influencer modes are interpreted in the same way. The coefficient estimates for a linear regression with a single categorical explanatory variable are identical to the grouped means of each category, it is vital to note. This indicates that we will obtain the same outcomes as the coefficient estimates above if we group the data by influencer and compute the means for each group.
```{r}
my_data %>% 
  group_by(influencer) %>% 
  summarise(average_sales = mean(sales))
```



